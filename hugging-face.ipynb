{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-20T13:27:15.931805Z","iopub.execute_input":"2023-01-20T13:27:15.932501Z","iopub.status.idle":"2023-01-20T13:27:15.942370Z","shell.execute_reply.started":"2023-01-20T13:27:15.932389Z","shell.execute_reply":"2023-01-20T13:27:15.941798Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:15.944223Z","iopub.execute_input":"2023-01-20T13:27:15.944892Z","iopub.status.idle":"2023-01-20T13:27:23.967622Z","shell.execute_reply.started":"2023-01-20T13:27:15.944842Z","shell.execute_reply":"2023-01-20T13:27:23.966608Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.5.1)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.8.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.5.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"def extract_data(path_in,path_out,col):\n    data_df = pd.read_csv(path_in)\n    data_df = data_df[col].fillna(0)\n    data_df.to_csv(path_out,index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:23.969937Z","iopub.execute_input":"2023-01-20T13:27:23.970319Z","iopub.status.idle":"2023-01-20T13:27:23.976765Z","shell.execute_reply.started":"2023-01-20T13:27:23.970253Z","shell.execute_reply":"2023-01-20T13:27:23.975927Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def split_data(data_df):\n    n = len(data_df)\n    train_df = data_df[:int(0.9*n)]\n    validate_df = data_df[int(0.9*n):]\n    return train_df,validate_df","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:23.978039Z","iopub.execute_input":"2023-01-20T13:27:23.978566Z","iopub.status.idle":"2023-01-20T13:27:23.988171Z","shell.execute_reply.started":"2023-01-20T13:27:23.978505Z","shell.execute_reply":"2023-01-20T13:27:23.987173Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"aux_columns = ['severe_toxicity','obscene','identity_attack','insult','threat','sexual_explicit']\nidentity_columns = [ 'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n                      'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\nspe_columns = ['black','white','homosexual_gay_or_lesbian','muslim']          \n\npath_out = \"/kaggle/input/jigsawnlp/reduced_train.csv\"\n\nif  not os.path.exists(path_out):\n    path_in = \"/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\"\n    #col = ['comment_text','target']+aux_columns+identity_columns\n    col = ['target']+aux_columns+identity_columns\n    extract_data(path_in,path_out,col)\n\ndata_df = pd.read_csv(path_out)\ntrain_df,validate_df = split_data(data_df)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:23.991735Z","iopub.execute_input":"2023-01-20T13:27:23.992620Z","iopub.status.idle":"2023-01-20T13:27:34.624960Z","shell.execute_reply.started":"2023-01-20T13:27:23.992564Z","shell.execute_reply":"2023-01-20T13:27:34.624000Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/input/jigsawnlp1/extract.py extract.py\n!cp /kaggle/input/jigsawnlp1/metrics.py metrics.py\n!cp /kaggle/input/jigsawnlp1/warmup.py warmup.py","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:34.626742Z","iopub.execute_input":"2023-01-20T13:27:34.627097Z","iopub.status.idle":"2023-01-20T13:27:37.973269Z","shell.execute_reply.started":"2023-01-20T13:27:34.627054Z","shell.execute_reply":"2023-01-20T13:27:37.972190Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def adapt_weight(df):\n    #The based weight\n    weights = np.ones(len(df)) / 4\n\n    # Subgroup  positive  \n    temp_index = (df[identity_columns].values>=0.5).max(axis=1)\n    weights[temp_index] += 0.25\n\n    # Background Positive, Subgroup Negative\n    temp_index = (df['target'].values>=0.5) * ((df[identity_columns].values<0.5).sum(axis=1) == len(identity_columns))\n    weights[temp_index] += 0.25\n\n    # Background Negative, Subgroup Positive\n    temp_index = (df['target'].values<0.5) * (df[identity_columns].values>=0.5).max(axis=1)\n    weights[temp_index] += 0.25\n\n    # Background Positive, special-Subgroup Negative\n    temp_index = (df['target'].values>=0.5) * ((df[spe_columns].values<0.5).sum(axis=1) == len(spe_columns))\n    weights[temp_index] += 0.125\n\n    # Background Positive, special-Subgroup Positive  \n    temp_index = (df['target'].values<0.5) * (df[spe_columns].values>=0.5).max(axis=1)\n    weights[temp_index] += 0.125\n\n    return weights","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:37.974817Z","iopub.execute_input":"2023-01-20T13:27:37.975287Z","iopub.status.idle":"2023-01-20T13:27:37.984427Z","shell.execute_reply.started":"2023-01-20T13:27:37.975239Z","shell.execute_reply":"2023-01-20T13:27:37.983391Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# weights for different training samples, weights_scale is used for normalization\nweights = adapt_weight(train_df)\nweights_scale = 1./weights.mean()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:37.985638Z","iopub.execute_input":"2023-01-20T13:27:37.985886Z","iopub.status.idle":"2023-01-20T13:27:38.309822Z","shell.execute_reply.started":"2023-01-20T13:27:37.985857Z","shell.execute_reply":"2023-01-20T13:27:38.308816Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.losses import  binary_crossentropy\n\nfrom extract import Extract\nfrom warmup import AdamWarmup\nimport metrics","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:38.311299Z","iopub.execute_input":"2023-01-20T13:27:38.311688Z","iopub.status.idle":"2023-01-20T13:27:40.533289Z","shell.execute_reply.started":"2023-01-20T13:27:38.311645Z","shell.execute_reply":"2023-01-20T13:27:40.532400Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2023-01-20 13:27:38.454987: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-01-20 13:27:38.455043: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"}]},{"cell_type":"code","source":"# TPU activation\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n    print(f'Running on TPU {tpu.master()}')\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:40.534718Z","iopub.execute_input":"2023-01-20T13:27:40.534956Z","iopub.status.idle":"2023-01-20T13:27:45.629731Z","shell.execute_reply.started":"2023-01-20T13:27:40.534928Z","shell.execute_reply":"2023-01-20T13:27:45.628899Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Running on TPU grpc://10.0.0.2:8470\n","output_type":"stream"},{"name":"stderr","text":"2023-01-20 13:27:40.538379: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2023-01-20 13:27:40.538747: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-01-20 13:27:40.538771: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2023-01-20 13:27:40.538800: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f66320cd2926): /proc/driver/nvidia/version does not exist\n2023-01-20 13:27:40.539375: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-20 13:27:40.539829: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2023-01-20 13:27:40.555962: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-01-20 13:27:40.556021: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30163}\n2023-01-20 13:27:40.572355: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-01-20 13:27:40.572432: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30163}\n2023-01-20 13:27:40.573102: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30163\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\nfrom transformers import BertTokenizer, TFBertModel\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n#model = TFBertModel.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:45.631204Z","iopub.execute_input":"2023-01-20T13:27:45.631947Z","iopub.status.idle":"2023-01-20T13:27:47.834670Z","shell.execute_reply.started":"2023-01-20T13:27:45.631894Z","shell.execute_reply":"2023-01-20T13:27:47.833867Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"lr = 3e-5\nweight_decay = 0.01\nnb_epochs=1\nbsz = 64\nmax_len=220\n\ndecay_steps = int(1.2*nb_epochs*len(train_df)/bsz)\nwarmup_steps = int(0.05*decay_steps)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:47.836009Z","iopub.execute_input":"2023-01-20T13:27:47.836342Z","iopub.status.idle":"2023-01-20T13:27:47.841952Z","shell.execute_reply.started":"2023-01-20T13:27:47.836302Z","shell.execute_reply":"2023-01-20T13:27:47.840948Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def custom_loss(y_true, y_pred):\n    # y_true : shape is n*2, cols = ['target', 'weights']\n    return binary_crossentropy(K.reshape(y_true[:,0],(-1,1)),y_pred,from_logits=False) * y_true[:,1]","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:47.843629Z","iopub.execute_input":"2023-01-20T13:27:47.843940Z","iopub.status.idle":"2023-01-20T13:27:47.853548Z","shell.execute_reply.started":"2023-01-20T13:27:47.843900Z","shell.execute_reply":"2023-01-20T13:27:47.852759Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def createmodel(model, weights_scale, max_len= 220):\n    adamwarm = AdamWarmup(decay_steps = decay_steps, warmup_steps = warmup_steps, \n                          learning_rate=lr, weight_decay = weight_decay,weight_decay_pattern=[\"embeddings\",\"kernel\",\"weight\"])\n\n    #define 3 types of input\n    input_ids = tf.keras.layers.Input(shape = (max_len,),dtype='int32', name = 'input_ids')\n    token_type_ids = tf.keras.layers.Input(shape = (max_len,),dtype='int32', name = 'token_type_ids')\n    attention_mask = tf.keras.layers.Input(shape = (max_len,),dtype='int32', name = 'attention_mask')\n\n    #\n    last_hidden_states = model(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask= attention_mask)[0]\n    cls_output = Extract(0)(last_hidden_states)\n\n    pool_output = tf.keras.layers.Dense(units=1, activation='sigmoid',name='real_output')(cls_output)\n    aux_output = tf.keras.layers.Dense(units=6, activation='sigmoid',name='aux_output')(cls_output)\n\n\n    train_model  = tf.keras.models.Model(inputs=[input_ids,token_type_ids,attention_mask], outputs=[pool_output,aux_output])\n    train_model.compile(loss=[custom_loss,'binary_crossentropy'],loss_weights=[weights_scale,6.], optimizer=adamwarm)\n    return train_model\n","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:47.857346Z","iopub.execute_input":"2023-01-20T13:27:47.857615Z","iopub.status.idle":"2023-01-20T13:27:47.868072Z","shell.execute_reply.started":"2023-01-20T13:27:47.857587Z","shell.execute_reply":"2023-01-20T13:27:47.867224Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n    train_model = createmodel(model,weights_scale)\ntrain_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:27:47.869360Z","iopub.execute_input":"2023-01-20T13:27:47.869628Z","iopub.status.idle":"2023-01-20T13:28:06.493853Z","shell.execute_reply.started":"2023-01-20T13:27:47.869599Z","shell.execute_reply":"2023-01-20T13:28:06.492596Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_ids (InputLayer)          [(None, 220)]        0                                            \n__________________________________________________________________________________________________\nattention_mask (InputLayer)     [(None, 220)]        0                                            \n__________________________________________________________________________________________________\ntoken_type_ids (InputLayer)     [(None, 220)]        0                                            \n__________________________________________________________________________________________________\ntf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n                                                                 attention_mask[0][0]             \n                                                                 token_type_ids[0][0]             \n__________________________________________________________________________________________________\nextract (Extract)               (None, 768)          0           tf_bert_model[0][0]              \n__________________________________________________________________________________________________\nreal_output (Dense)             (None, 1)            769         extract[0][0]                    \n__________________________________________________________________________________________________\naux_output (Dense)              (None, 6)            4614        extract[0][0]                    \n==================================================================================================\nTotal params: 109,487,623\nTrainable params: 109,487,623\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_df_input(train_df,max_len):\n    train_input = tokenizer(list(train_df), return_tensors='tf',padding=\"max_length\", truncation=True, max_length=max_len)\n    input_ids = train_input[\"input_ids\"]\n    attention_mask = train_input[\"attention_mask\"]\n    token_type_ids = train_input[\"token_type_ids\"]\n    return  input_ids, attention_mask, token_type_ids","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:28:06.495612Z","iopub.execute_input":"2023-01-20T13:28:06.495948Z","iopub.status.idle":"2023-01-20T13:28:06.502363Z","shell.execute_reply.started":"2023-01-20T13:28:06.495917Z","shell.execute_reply":"2023-01-20T13:28:06.501500Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"token = [\"train_input_ids\",\"train_attention_mask\",\"train_token_type_ids\",\n        \"validate_input_ids\",\"validate_attention_mask\",\"validate_token_type_ids\"]\n\nfor t in token:\n    temp_path = \"/kaggle/input/jigsaw-input-token/\"+t+\".npy\"\n    if  os.path.exists(temp_path):\n        globals()[t] = np.load(temp_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:15:13.366966Z","iopub.execute_input":"2023-01-20T14:15:13.367306Z","iopub.status.idle":"2023-01-20T14:15:50.977698Z","shell.execute_reply.started":"2023-01-20T14:15:13.367275Z","shell.execute_reply":"2023-01-20T14:15:50.976078Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_aux_target = np.array(train_df[aux_columns])\n\n# y_true : shape is n*2, cols = ['target', 'weights']\ny_true = np.concatenate( [np.array(train_df[\"target\"]).reshape(-1,1), weights.reshape(-1,1)],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:28:24.084032Z","iopub.execute_input":"2023-01-20T13:28:24.084398Z","iopub.status.idle":"2023-01-20T13:28:24.172645Z","shell.execute_reply.started":"2023-01-20T13:28:24.084353Z","shell.execute_reply":"2023-01-20T13:28:24.171544Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_model.fit([train_input_ids, train_attention_mask, train_token_type_ids ],[y_true,train_aux_target],batch_size = 128)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:28:24.173922Z","iopub.execute_input":"2023-01-20T13:28:24.174174Z","iopub.status.idle":"2023-01-20T13:59:46.663397Z","shell.execute_reply.started":"2023-01-20T13:28:24.174146Z","shell.execute_reply":"2023-01-20T13:59:46.660935Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"2023-01-20 13:28:24.183754: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1429459680 exceeds 10% of free system memory.\n2023-01-20 13:28:27.832880: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1429459680 exceeds 10% of free system memory.\n2023-01-20 13:28:30.724452: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1429459680 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"12691/12691 [==============================] - 1868s 140ms/step - loss: 0.8568 - real_output_loss: 0.1008 - aux_output_loss: 0.0902\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f94178c05d0>"},"metadata":{}}]},{"cell_type":"code","source":"y_predict = train_model.predict([validate_input_ids, validate_attention_mask, validate_token_type_ids ])[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:15:50.981681Z","iopub.execute_input":"2023-01-20T14:15:50.982681Z","iopub.status.idle":"2023-01-20T14:17:20.035640Z","shell.execute_reply.started":"2023-01-20T14:15:50.982635Z","shell.execute_reply":"2023-01-20T14:17:20.034836Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"y_gt = np.array(validate_df['target'])","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:17:20.036824Z","iopub.execute_input":"2023-01-20T14:17:20.037199Z","iopub.status.idle":"2023-01-20T14:17:20.042648Z","shell.execute_reply.started":"2023-01-20T14:17:20.037170Z","shell.execute_reply":"2023-01-20T14:17:20.042082Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"validate_df[\"predict\"]=y_predict.flatten()\nbias_metrics_df = metrics.compute_bias_metrics_for_model(validate_df, identity_columns,\"target\",\"predict\")\nbias_metrics_df","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:17:21.376345Z","iopub.execute_input":"2023-01-20T14:17:21.376655Z","iopub.status.idle":"2023-01-20T14:17:22.319484Z","shell.execute_reply.started":"2023-01-20T14:17:21.376617Z","shell.execute_reply":"2023-01-20T14:17:22.318545Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n6                          black           1614      0.877252  0.948345   \n2      homosexual_gay_or_lesbian           1185      0.899905  0.935644   \n7                          white           2801      0.901140  0.954904   \n5                         muslim           1845      0.912248  0.965550   \n4                         jewish            545      0.919888  0.967089   \n0                           male           4811      0.945273  0.965258   \n1                         female           6743      0.949975  0.968282   \n3                      christian           3381      0.951369  0.974083   \n8  psychiatric_or_mental_illness            490      0.957611  0.950399   \n\n   bnsp_auc  \n6  0.954751  \n2  0.963379  \n7  0.958379  \n5  0.951460  \n4  0.951181  \n0  0.967306  \n1  0.967042  \n3  0.960203  \n8  0.980646  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subgroup</th>\n      <th>subgroup_size</th>\n      <th>subgroup_auc</th>\n      <th>bpsn_auc</th>\n      <th>bnsp_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>black</td>\n      <td>1614</td>\n      <td>0.877252</td>\n      <td>0.948345</td>\n      <td>0.954751</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>homosexual_gay_or_lesbian</td>\n      <td>1185</td>\n      <td>0.899905</td>\n      <td>0.935644</td>\n      <td>0.963379</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>white</td>\n      <td>2801</td>\n      <td>0.901140</td>\n      <td>0.954904</td>\n      <td>0.958379</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>muslim</td>\n      <td>1845</td>\n      <td>0.912248</td>\n      <td>0.965550</td>\n      <td>0.951460</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>jewish</td>\n      <td>545</td>\n      <td>0.919888</td>\n      <td>0.967089</td>\n      <td>0.951181</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>4811</td>\n      <td>0.945273</td>\n      <td>0.965258</td>\n      <td>0.967306</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>6743</td>\n      <td>0.949975</td>\n      <td>0.968282</td>\n      <td>0.967042</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>christian</td>\n      <td>3381</td>\n      <td>0.951369</td>\n      <td>0.974083</td>\n      <td>0.960203</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>psychiatric_or_mental_illness</td>\n      <td>490</td>\n      <td>0.957611</td>\n      <td>0.950399</td>\n      <td>0.980646</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"metrics.get_final_metric(bias_metrics_df, metrics.calculate_overall_auc(validate_df,\"target\",\"predict\"))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:17:22.320744Z","iopub.execute_input":"2023-01-20T14:17:22.321001Z","iopub.status.idle":"2023-01-20T14:17:22.387140Z","shell.execute_reply.started":"2023-01-20T14:17:22.320972Z","shell.execute_reply":"2023-01-20T14:17:22.386204Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0.9547544681799787"},"metadata":{}}]}]}